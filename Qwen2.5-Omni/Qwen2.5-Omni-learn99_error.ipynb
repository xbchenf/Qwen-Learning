{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70da7793-2bc0-4298-bf95-5b0319de3565",
   "metadata": {},
   "source": [
    "# 错误信息汇总处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b11e49-cbf1-4233-a6f2-ca11b09787ed",
   "metadata": {},
   "source": [
    "# 安装flash-attn 报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfe556-f11a-4fa3-b001-85b05da5fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /root/miniconda3/lib/python3.12/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
    "Building wheels for collected packages: flash-attn\n",
    "  Building wheel for flash-attn (setup.py) ... error\n",
    "  error: subprocess-exited-with-error\n",
    "  \n",
    "  × python setup.py bdist_wheel did not run successfully.\n",
    "  │ exit code: 1\n",
    "  ╰─> [18 lines of output]\n",
    "      \n",
    "      \n",
    "      torch.__version__  = 2.3.0+cu121\n",
    "      \n",
    "      \n",
    "      /root/miniconda3/lib/python3.12/site-packages/setuptools/__init__.py:81: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
    "      !!\n",
    "      \n",
    "              ********************************************************************************\n",
    "              Requirements should be satisfied by a PEP 517 installer.\n",
    "              If you are using pip, you can try `pip install --use-pep517`.\n",
    "              ********************************************************************************\n",
    "      \n",
    "      !!\n",
    "        dist.fetch_build_eggs(dist.setup_requires)\n",
    "      running bdist_wheel\n",
    "      Guessing wheel URL:  https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.3cxx11abiFALSE-cp312-cp312-linux_x86_64.whl\n",
    "      error: Remote end closed connection without response\n",
    "      [end of output]\n",
    "  \n",
    "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
    "  ERROR: Failed building wheel for flash-attn\n",
    "  Running setup.py clean for flash-attn\n",
    "Failed to build flash-attn\n",
    "ERROR: Could not build wheels for flash-attn, which is required to install pyproject.toml-based projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acbc89e-e214-4a1c-8ddf-0022c643da06",
   "metadata": {},
   "source": [
    "\n",
    "## 问题分析\n",
    "依赖问题：flash-attn 依赖于 torch 和其他库，而安装过程中可能由于某些依赖未正确处理导致失败。\n",
    "依赖冲突：torch 和 flash-attn 的版本不兼容。\n",
    "\n",
    "## 处理方案\n",
    "更新flash-attn版本\n",
    "pip install -U flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b865d-8abb-488b-8463-81c29ff2f5d9",
   "metadata": {},
   "source": [
    "## transformers推理报错（一）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137f929-a54e-471b-9a45-5a14f47afb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "File ~/miniconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1951, in _LazyModule._get_module(self, module_name)\n",
    "   1949     return importlib.import_module(\".\" + module_name, self.__name__)\n",
    "   1950 except Exception as e:\n",
    "-> 1951     raise RuntimeError(\n",
    "   1952         f\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\n",
    "   1953         f\" traceback):\\n{e}\"\n",
    "   1954     ) from e\n",
    "\n",
    "RuntimeError: Failed to import transformers.models.qwen2_5_omni.modeling_qwen2_5_omni because of the following error (look up to see its traceback):\n",
    "No module named 'triton'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df709a5-7b54-47b0-8316-fe28f621ccee",
   "metadata": {},
   "source": [
    "## 解决方案\n",
    "根据错误信息: RuntimeError: Failed to import transformers.models.qwen2_5_omni.modeling_qwen2_5_omni because of the following error (look up to see its traceback):\n",
    "No module named 'triton'\n",
    "可以看出来，缺少了triton模块\n",
    "```bash\n",
    "pip install triton\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d71042-5e4f-4f9e-ac18-8be89fa08b8d",
   "metadata": {},
   "source": [
    "## transformers推理报错（二）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b92e92-beaa-47c9-a98c-9db71d22ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "File ~/miniconda3/lib/python3.12/site-packages/qwen_omni_utils/v2_5/audio_process.py:46, in process_audio_info(conversations, use_audio_in_video)\n",
    "     42 assert _check_if_video_has_audio(\n",
    "     43     path\n",
    "     44 ), \"Video must has audio track when use_audio_in_video=True\"\n",
    "     45 if path.startswith(\"http://\") or path.startswith(\"https://\"):\n",
    "---> 46     audios.append(librosa.load(audioread.ffdec.FFmpegAudioFile(path), sr=16000)[0])\n",
    "     47 elif path.startswith(\"file://\"):\n",
    "     48     audios.append(librosa.load(path[len(\"file://\") :], sr=16000)[0])\n",
    "\n",
    "File ~/miniconda3/lib/python3.12/site-packages/audioread/ffdec.py:152, in FFmpegAudioFile.__init__(self, filename, block_size)\n",
    "    142     self.proc = popen_multiple(\n",
    "    143         COMMANDS,\n",
    "    144         ['-i', filename, '-f', 's16le', '-'],\n",
    "   (...)\n",
    "    148         creationflags=PROC_FLAGS,\n",
    "    149     )\n",
    "    151 except OSError:\n",
    "--> 152     raise NotInstalledError()\n",
    "    154 finally:\n",
    "    155     # Reset previous error mode on Windows. (We can change this\n",
    "    156     # back now because the flag was inherited by the subprocess;\n",
    "    157     # we don't need to keep it set in the parent process.)\n",
    "    158     if windows:\n",
    "\n",
    "NotInstalledError:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0875af-4349-48e4-baaf-d350ad2e27b1",
   "metadata": {},
   "source": [
    "### 问题分析\n",
    "1. **错误位置**：\n",
    "   - 错误发生在 `qwen_omni_utils/v2_5/audio_process.py` 文件的第 46 行，具体代码为：\n",
    "     ```python\n",
    "     audios.append(librosa.load(audioread.ffdec.FFmpegAudioFile(path), sr=16000)[0])\n",
    "     ```\n",
    "   - 这行代码尝试通过 `librosa` 和 `audioread` 加载音频文件。`audioread` 使用 `ffmpeg` 作为后端来处理音频文件。\n",
    "\n",
    "2. **错误原因**：\n",
    "   - `audioread` 在尝试调用 `ffmpeg` 时，发现 `ffmpeg` 未安装或未正确配置，因此抛出了 `NotInstalledError` 异常。\n",
    "\n",
    "3. **依赖关系**：\n",
    "   - `audioread` 是一个用于读取音频文件的库，它依赖于 `ffmpeg` 来处理音频文件。\n",
    "   - `librosa` 是一个音频处理库，它内部使用 `audioread` 来加载音频文件。\n",
    "\n",
    "### 解决方法\n",
    "#### 1. 安装 `ffmpeg`\n",
    "确保 `ffmpeg` 已正确安装并可以在系统中使用。以下是安装方法：\n",
    "\n",
    "- **在 Linux 上安装**：\n",
    "  ```bash\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install ffmpeg\n",
    "  ```\n",
    "\n",
    "- **在 macOS 上安装**：\n",
    "  ```bash\n",
    "  brew install ffmpeg\n",
    "  ```\n",
    "\n",
    "- **在 Windows 上安装**：\n",
    "  1. 下载 `ffmpeg` 的预编译版本：[FFmpeg Download](https://ffmpeg.org/download.html)\n",
    "  2. 解压下载的文件，并将 `bin` 文件夹路径添加到系统的环境变量 `PATH` 中。\n",
    "\n",
    "#### 2. 验证 `ffmpeg` 是否安装成功\n",
    "在终端中运行以下命令，检查 `ffmpeg` 是否正确安装：\n",
    "```bash\n",
    "ffmpeg -version\n",
    "```\n",
    "如果安装成功，你应该能看到 `ffmpeg` 的版本信息。\n",
    "\n",
    "\n",
    "#### 3. 确保 `audioread` 和 `librosa` 使用正确的 `ffmpeg` 路径\n",
    "如果 `ffmpeg` 已安装，但仍然报错，可能是因为 `audioread` 或 `librosa` 无法找到 `ffmpeg` 的路径。可以通过以下方法解决：\n",
    "\n",
    "- **设置环境变量**：\n",
    "  在终端中运行以下命令，设置 `ffmpeg` 的路径（假设 `ffmpeg` 已安装在 `/usr/bin/ffmpeg`）：\n",
    "  ```bash\n",
    "  export AUDIOREAD_FFMPEG_PATH=/usr/bin/ffmpeg\n",
    "  ```\n",
    "\n",
    "- **在代码中指定 `ffmpeg` 路径**：\n",
    "  如果你无法修改环境变量，可以在代码中显式指定 `ffmpeg` 的路径。例如：\n",
    "  ```python\n",
    "  import os\n",
    "  os.environ['AUDIOREAD_FFMPEG_PATH'] = '/usr/bin/ffmpeg'\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f4e8b-5ab3-48b0-90d6-5dd257951aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root@autodl-container-4ed149a141-6d10b153:~# ffmpeg -version\n",
    "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
    "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
    "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
    "libavutil      56. 70.100 / 56. 70.100\n",
    "libavcodec     58.134.100 / 58.134.100\n",
    "libavformat    58. 76.100 / 58. 76.100\n",
    "libavdevice    58. 13.100 / 58. 13.100\n",
    "libavfilter     7.110.100 /  7.110.100\n",
    "libswscale      5.  9.100 /  5.  9.100\n",
    "libswresample   3.  9.100 /  3.  9.100\n",
    "libpostproc    55.  9.100 / 55.  9.100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc36f8-2aab-497e-b73c-e47eb395dc62",
   "metadata": {},
   "source": [
    "# transformers推理报错（三）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69b61b-0bdb-4f49-bea3-02c8467862ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "File ~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:1945, in GenerationMixin._prepare_special_tokens(self, generation_config, kwargs_has_attention_mask, device)\n",
    "   1939     raise ValueError(\n",
    "   1940         \"`decoder_start_token_id` or `bos_token_id` has to be defined for encoder-decoder generation.\"\n",
    "   1941     )\n",
    "   1942 if not is_torchdynamo_compiling():  # Checks that depend on tensor-dependent control flow\n",
    "   1943     if (\n",
    "   1944         eos_token_tensor is not None\n",
    "-> 1945         and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()\n",
    "   1946     ):\n",
    "   1947         if kwargs_has_attention_mask is not None and not kwargs_has_attention_mask:\n",
    "   1948             logger.warning_once(\n",
    "   1949                 \"The attention mask is not set and cannot be inferred from input because pad token is same as \"\n",
    "   1950                 \"eos token. As a consequence, you may observe unexpected behavior. Please pass your input's \"\n",
    "   1951                 \"`attention_mask` to obtain reliable results.\"\n",
    "   1952             )\n",
    "\n",
    "NotImplementedError: aten::_local_scalar_dense: attempted to run this operator with Meta tensors, but there was no abstract impl or Meta kernel registered. You may have run into this message while using an operator with PT2 compilation APIs (torch.compile/torch.export); in order to use this operator with those APIs you'll need to add an abstract impl.Please see the following doc for next steps: https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fe092-0f68-4c22-9306-a535e97422c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU资源查看如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d7fd3-c0f8-43f7-b14f-07b425ae9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "root@autodl-container-4ed149a141-6d10b153:~/autodl-tmp# nvidia-smi\n",
    "Wed Apr  2 08:58:52 2025       \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA vGPU-32GB               On  |   00000000:2E:00.0 Off |                  N/A |\n",
    "| 30%   30C    P8              7W /  320W |   22029MiB /  32760MiB |      0%      Default |\n",
    "|                                         |                        |                  N/A |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "                                                                                         \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "|    0   N/A  N/A      1447      C   /root/miniconda3/bin/python                     0MiB |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc9799-08ca-45b3-bfc9-e909198c8c26",
   "metadata": {},
   "source": [
    "清理和释放 GPU 资源的步骤（可以先尝试重启内核，不行再进行kill进程）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca44014-fa08-4dfb-a4ea-6ae707222506",
   "metadata": {},
   "source": [
    "\n",
    "在 Linux 系统中，清理和释放 GPU 资源通常需要终止占用 GPU 的进程。根据你提供的 `nvidia-smi` 输出，当前有一个 Python 进程（PID 1447）正在运行，但它的 GPU 内存占用为 0 MiB。然而，GPU 的总内存使用达到了 22 GB，这表明可能存在其他未列出的进程占用了 GPU 内存。\n",
    "\n",
    "以下是清理和释放 GPU 资源的方式：\n",
    "\n",
    "### 1. **查找并终止占用 GPU 的进程**\n",
    "\n",
    "#### 使用 `nvidia-smi` 查找进程\n",
    "运行以下命令，查找所有占用 GPU 的进程：\n",
    "```bash\n",
    "nvidia-smi pmon -s u\n",
    "```\n",
    "这个命令会显示更详细的 GPU 进程信息，包括每个进程的内存使用情况。\n",
    "\n",
    "#### 终止进程\n",
    "找到占用 GPU 内存的进程后，可以使用 `kill` 命令终止它们。例如：\n",
    "```bash\n",
    "kill -9 <PID>\n",
    "```\n",
    "将 `<PID>` 替换为实际的进程 ID。\n",
    "\n",
    "### 2. **清理 GPU 缓存**\n",
    "\n",
    "#### 使用 PyTorch 清理 GPU 缓存\n",
    "如果你使用的是 PyTorch，可以在代码中显式清理 GPU 缓存：\n",
    "```python\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "### 3. 重启系统\n",
    "如果所有方法都无法释放 GPU 资源，重启系统是最直接的方法：\n",
    "sudo reboot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fb1b88-c5f7-42d9-93bd-5cb382659790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers推理报错（四）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c882f95-a2a0-4742-a46a-31f1c1b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "NotInstalledError                         Traceback (most recent call last)\n",
    "Cell In[3], line 5\n",
    "      2 video_path = \"files/music.mp4\"\n",
    "      4 display(Video(video_path, width=640, height=360))\n",
    "----> 5 display(Audio(librosa.load(audioread.ffdec.FFmpegAudioFile(video_path), sr=16000)[0], rate=16000))\n",
    "      7 ## Use a local HuggingFace model to inference.\n",
    "      8 response, audio  = inference(video_path)\n",
    "\n",
    "File ~/miniconda3/lib/python3.12/site-packages/audioread/ffdec.py:152, in FFmpegAudioFile.__init__(self, filename, block_size)\n",
    "    142     self.proc = popen_multiple(\n",
    "    143         COMMANDS,\n",
    "    144         ['-i', filename, '-f', 's16le', '-'],\n",
    "   (...)\n",
    "    148         creationflags=PROC_FLAGS,\n",
    "    149     )\n",
    "    151 except OSError:\n",
    "--> 152     raise NotInstalledError()\n",
    "    154 finally:\n",
    "    155     # Reset previous error mode on Windows. (We can change this\n",
    "    156     # back now because the flag was inherited by the subprocess;\n",
    "    157     # we don't need to keep it set in the parent process.)\n",
    "    158     if windows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7f185-8792-49cc-ad97-6e34cbc9b5be",
   "metadata": {},
   "source": [
    "## 问题分析：\n",
    "`NotInstalledError` 是由 `audioread` 库抛出的异常，通常是因为以下原因之一：\n",
    "- **FFmpeg 未安装**：`audioread` 依赖 FFmpeg 来处理音频文件，但系统中未安装 FFmpeg。\n",
    "- **FFmpeg 未正确配置**：即使安装了 FFmpeg，但系统无法找到其可执行文件路径。\n",
    "- **环境变量问题**：FFmpeg 的路径未添加到系统的环境变量中。\n",
    "\n",
    "## 解决方案\n",
    "\n",
    "### **方法 1：检查 FFmpeg 是否安装**\n",
    "1. 打开终端或命令提示符。\n",
    "2. 输入以下命令检查 FFmpeg 是否安装：\n",
    "   ```bash\n",
    "   ffmpeg -version\n",
    "   ```\n",
    "   如果返回 FFmpeg 的版本信息，则说明 FFmpeg 已安装；如果没有返回任何信息或提示命令未找到，则需要安装 FFmpeg。\n",
    "\n",
    "### **方法 2：安装 FFmpeg**\n",
    "根据你的操作系统，安装 FFmpeg 的方法如下：\n",
    "\n",
    "- **Windows**：\n",
    "  1. 访问 [FFmpeg 官方下载页面](https://ffmpeg.org/download.html)。\n",
    "  2. 下载适合 Windows 的静态构建版本（通常是一个 `.zip` 文件）。\n",
    "  3. 解压下载的文件到一个目录，例如 `C:\\ffmpeg`。\n",
    "  4. 将 `C:\\ffmpeg\\bin` 添加到系统的环境变量中：\n",
    "     - 右键点击“此电脑”或“我的电脑”，选择“属性”。\n",
    "     - 点击“高级系统设置”。\n",
    "     - 在“系统属性”窗口中，点击“环境变量”。\n",
    "     - 在“系统变量”中找到 `Path`，点击“编辑”。\n",
    "     - 添加 `C:\\ffmpeg\\bin` 到变量值中。\n",
    "     - 点击“确定”保存更改。\n",
    "\n",
    "- **macOS**：\n",
    "  1. 使用 Homebrew 安装 FFmpeg：\n",
    "     ```bash\n",
    "     brew install ffmpeg\n",
    "     ```\n",
    "\n",
    "- **Linux**：\n",
    "  1. 使用包管理器安装 FFmpeg。例如，在 Ubuntu 或 Debian 上：\n",
    "     ```bash\n",
    "     sudo apt update\n",
    "     sudo apt install ffmpeg\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfdf0d0-053f-4268-b8c2-49de3274ba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
